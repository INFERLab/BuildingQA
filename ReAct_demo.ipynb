{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddf03f3f",
   "metadata": {},
   "source": [
    "# Knowledge Graph Question Answering for Building Knowledge Graphs using a ReAct Framework\n",
    "\n",
    "This notebook implements an agentic workflow based on the **ReAct (Reasoning and Acting)** framework to translate natural language questions into precise SPARQL queries. The core of this notebook is a multi-turn refinement process where two specialized agents collaborate to produce, critique, and improve a SPARQL query until it is deemed correct.\n",
    "\n",
    "---\n",
    "\n",
    "## ü§ñ Methodology: The Two-Agent Loop\n",
    "\n",
    "The agentic workflow is orchestrated by the `SparqlRefinementAgent` class and consists of an iterative loop between two Large Language Model (LLM) powered agents:\n",
    "\n",
    "1.  **Query Writer Agent**:\n",
    "    * **Role**: To generate and revise SPARQL queries.\n",
    "    * **Action**: Given a natural language question and a subset (defined by `num_triples` of the graph) of the graph, it writes an initial SPARQL query. In subsequent turns, it revises the query based on feedback.\n",
    "\n",
    "2.  **Critique Agent**:\n",
    "    * **Role**: To evaluate the query's correctness.\n",
    "    * **Action**: After the Writer's query is executed, the Critique agent reviews the original question, the query itself, and a summary of the execution results. It then makes a decision:\n",
    "        * `FINAL`: The query is correct and successfully answers the question. The loop terminates.\n",
    "        * `IMPROVE`: The query is incorrect, incomplete, or inefficient. The agent provides specific, actionable feedback.\n",
    "\n",
    "This feedback is then passed back to the Query Writer Agent, which begins the next iteration by generating an improved query. This cycle continues until a `FINAL` decision is reached or the maximum number of iterations is exceeded.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Execution Workflow\n",
    "\n",
    "The notebook follows a systematic process for each building and question:\n",
    "\n",
    "1.  **Configuration**: Configure your API keys and URL for LLM calls.\n",
    "2.  **Initialize Agents**: The `SparqlRefinementAgent` is instantiated.\n",
    "3.  **Define a helper function for testing a single question**: `run_single_question` function is defined for initial testing.\n",
    "4.  **Configure the necessary test conditions**: Key parameters such as the target building (`BUILDING_NAME`), LLM (`MODEL_NAME`), and SPARQL endpoint are set.\n",
    "5.  **Process All Questions and Buildings**: The script iterates through each question in the JSON file.\n",
    "    * The **ReAct loop** is triggered for the current question.\n",
    "    * The final query generated by the agent is executed.\n",
    "    * The ground-truth query is executed for comparison.\n",
    "    * Key metrics are computed and saved. \n",
    "\n",
    "---\n",
    "\n",
    "## üìä Evaluation Metrics\n",
    "\n",
    "To rigorously assess the correctness of the generated SPARQL query, the following metrics are calculated and logged:\n",
    "\n",
    "* **Arity Matching F1**: Checks if the query returned the correct **number of columns**.\n",
    "* **Exact Match F1**: A strict check for identical row content and column **order**, though it ignores column names.\n",
    "* **Entity Set F1**: Flexibly checks if the correct **sets of values** were retrieved in each column, regardless of row structure or column order.\n",
    "* **Row Matching F1**: The most robust metric. It finds the optimal column alignment and then checks for an exact, row-for-row match of the content. This is the primary indicator of a perfectly correct query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import traceback\n",
    "import uuid\n",
    "import warnings\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from pyparsing import ParseException\n",
    "from rdflib import BNode, Graph, Literal, URIRef\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from ReAct_agent.utils import get_kg_subset_content, extract_prefixes_from_ttl, check_if_question_exists, CsvLogger\n",
    "\n",
    "from ReAct_agent.sparql_refinement_agent import SparqlRefinementAgent \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdbd8bf",
   "metadata": {},
   "source": [
    "### 1. Assign your API key and your base url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750f3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\" # Change this to your actual API key for whatever service you are using or set it in your environment variables\n",
    "client = OpenAI(    \n",
    "    api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "    base_url=\"https://api.openai.com/v1/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97b556",
   "metadata": {},
   "source": [
    "### 2. Initialize The `SparqlRefinementAgent` (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"openai/o3-mini\"\n",
    "BUILDING_NAME = \"bldg11\"\n",
    "SPARQL_TARGET = f\"http://Ozans-MacBook-Pro-9.local:7200/repositories/{BUILDING_NAME}\" \n",
    "\n",
    "LOG_FIELDNAMES = [\n",
    "    'query_id', 'question_number', 'source', 'question', 'model',\n",
    "    'ground_truth_sparql', 'generated_sparql',\n",
    "    'syntax_ok', 'returns_results', 'perfect_match',\n",
    "    'gt_num_rows', 'gt_num_cols',\n",
    "    'gen_num_rows', 'gen_num_cols',\n",
    "    'arity_matching_f1',\n",
    "    'exact_match_f1',\n",
    "    'entity_set_f1',\n",
    "    'row_matching_f1',\n",
    "    'less_columns_flag',\n",
    "    'prompt_tokens', 'completion_tokens', 'total_tokens'\n",
    "]\n",
    "\n",
    "\n",
    "agent = SparqlRefinementAgent(\n",
    "    sparql_endpoint=SPARQL_TARGET, \n",
    "    model_name=MODEL_NAME, \n",
    "    max_iterations=3,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41989b",
   "metadata": {},
   "source": [
    "### 3. Define a helper function for testing a single question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895d38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_single_question():\n",
    "    # The script will automatically detect if the target is a file path or a URL\n",
    "    SPARQL_TARGET = LOCAL_TTL_PATH if USE_LOCAL_TTL_FILE else REMOTE_ENDPOINT_URL\n",
    "\n",
    "    BRICK_PREFIXES = extract_prefixes_from_ttl(LOCAL_TTL_PATH)\n",
    "\n",
    "    KNOWLEDGE_GRAPH_CONTENT = get_kg_subset_content(LOCAL_TTL_PATH, max_triples= num_triples)\n",
    "    print(\"First 1000 chars of knowledge graph content:\")\n",
    "    print(KNOWLEDGE_GRAPH_CONTENT[:1000])\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        all_data = json.load(f)\n",
    "    target_building_data = all_data[0]\n",
    "\n",
    "    if not os.path.exists(os.path.dirname(LOG_FILE)):\n",
    "        os.makedirs(os.path.dirname(LOG_FILE))\n",
    "\n",
    "    logger = CsvLogger(filename=LOG_FILE, fieldnames=LOG_FIELDNAMES)\n",
    "    agent = SparqlRefinementAgent(\n",
    "        sparql_endpoint=SPARQL_TARGET, \n",
    "        model_name=MODEL_NAME, \n",
    "        max_iterations=3,\n",
    "        client=client\n",
    "    )\n",
    "\n",
    "    print(f\"--- Processing building: {BUILDING_NAME} for model: {MODEL_NAME} ---\")\n",
    "\n",
    "    first_question_processed = False\n",
    "\n",
    "    try:\n",
    "        for query_info in target_building_data.get('queries', []):\n",
    "            query_id = query_info.get('query_id')\n",
    "            ground_truth_sparql = query_info.get('sparql_query')\n",
    "\n",
    "            if not ground_truth_sparql:\n",
    "                print(f\"‚ö†Ô∏è Warning: Skipping Query Group ID {query_id} (no ground truth SPARQL).\")\n",
    "                continue\n",
    "                \n",
    "            if \"prefix\" not in ground_truth_sparql.lower():\n",
    "                ground_truth_sparql = BRICK_PREFIXES + ground_truth_sparql\n",
    "\n",
    "            print(f\"\\n--- Processing Query Group ID: {query_id} ---\")\n",
    "            \n",
    "            for question_obj in query_info.get('questions', []):\n",
    "                question_text = question_obj.get('text')\n",
    "                if not question_text:\n",
    "                    continue\n",
    "\n",
    "                if check_if_question_exists(question_text, LOG_FILE, MODEL_NAME):\n",
    "                    print(f\"Question '{question_text[:50]}...' already logged. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                eval_data = {\n",
    "                    'query_id': query_id,\n",
    "                    'question_number': question_obj.get('question_number', 'N/A'),\n",
    "                    'source': question_obj.get('source', 'N/A'),\n",
    "                    'question': question_text,\n",
    "                    'ground_truth_sparql': ground_truth_sparql\n",
    "                }\n",
    "                \n",
    "                agent.refine_and_evaluate_query(\n",
    "                    eval_data=eval_data, \n",
    "                    logger=logger, \n",
    "                    prefixes=BRICK_PREFIXES,\n",
    "                    knowledge_graph_content=KNOWLEDGE_GRAPH_CONTENT\n",
    "                )\n",
    "                \n",
    "                # --- Set flag and break after the first processed question ---\n",
    "                print(\"\\nFirst question processed. Exiting loops.\")\n",
    "                first_question_processed = True\n",
    "                break # Exit the inner (questions) loop\n",
    "            # --- Check the flag to exit the outer loop as well ---\n",
    "            if first_question_processed:\n",
    "                break # Exit the outer (queries) loop\n",
    "\n",
    "    finally:\n",
    "        logger.close()\n",
    "        print(\"Logger closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cfa4e",
   "metadata": {},
   "source": [
    "###  4.Configure the necessary test conditions: \n",
    "Set key parameters such as the target building (`BUILDING_NAME`), LLM (`MODEL_NAME`), and SPARQL endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"openai/o3-mini\"\n",
    "BUILDING_NAME = \"bldg11\"\n",
    "num_triples = 100\n",
    "USE_LOCAL_TTL_FILE = False # We are using GraphDB for running queries. Convert this to True if you want to run queries locally.\n",
    "LOCAL_TTL_PATH = f\"./eval_buildings/{BUILDING_NAME}.ttl\"\n",
    "REMOTE_ENDPOINT_URL = f\"http://Ozans-MacBook-Pro-9.local:7200/repositories/{BUILDING_NAME}\" \n",
    "json_file_path = f\"./Benchmark_QA_pairs/{BUILDING_NAME}_combined.json\"\n",
    "LOG_FILE = f\"Example_Results/ReAct(w{num_triples})_{BUILDING_NAME}.csv\"\n",
    "\n",
    "run_single_question()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaecdeb",
   "metadata": {},
   "source": [
    "### 5. Process All Questions and Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026fe8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_buildings(model_name: str, num_triples: int):\n",
    "    # --- Configure your details here ---\n",
    "    for BUILDING_NAME in [\"b59\", \"bldg11\",\"TUC_building\",\"dflexlibs_multizone\"]:  \n",
    "        MODEL_NAME = model_name\n",
    "        # The script will automatically detect if the target is a file path or a URL\n",
    "        SPARQL_TARGET = LOCAL_TTL_PATH if USE_LOCAL_TTL_FILE else REMOTE_ENDPOINT_URL\n",
    "\n",
    "        LOG_FILE = f\"Results/ReAct(w{num_triples})_{BUILDING_NAME}.csv\"\n",
    "\n",
    "        # --- Dynamically get prefixes from the building's TTL file ---\n",
    "        # This now correctly points to the local ttl file regardless of the query target.\n",
    "        BRICK_PREFIXES = extract_prefixes_from_ttl(LOCAL_TTL_PATH)\n",
    "        if not BRICK_PREFIXES:\n",
    "            print(\"Could not extract prefixes. Exiting.\")\n",
    "            exit()\n",
    "        \n",
    "        KNOWLEDGE_GRAPH_CONTENT = get_kg_subset_content(LOCAL_TTL_PATH, max_triples= num_triples)\n",
    "        print(\"First 1000 chars of knowledge graph content:\")\n",
    "        print(KNOWLEDGE_GRAPH_CONTENT[:1000])\n",
    "\n",
    "        \n",
    "        try:\n",
    "            with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "                all_data = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå Error: The file '{json_file_path}' was not found.\")\n",
    "            exit()\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"‚ùå Error: The file '{json_file_path}' is not a valid JSON file.\")\n",
    "            exit()\n",
    "\n",
    "        if not isinstance(all_data, list) or not all_data:\n",
    "            print(f\"‚ùå Error: Expected JSON to be a non-empty list of building objects.\")\n",
    "            exit()\n",
    "        target_building_data = all_data[0]\n",
    "\n",
    "        #if log file dont exist, mkdir\n",
    "        if not os.path.exists(os.path.dirname(LOG_FILE)):\n",
    "            os.makedirs(os.path.dirname(LOG_FILE))\n",
    "\n",
    "\n",
    "        logger = CsvLogger(filename=LOG_FILE, fieldnames=LOG_FIELDNAMES)\n",
    "        agent = SparqlRefinementAgent(\n",
    "            sparql_endpoint=SPARQL_TARGET, \n",
    "            model_name=MODEL_NAME, \n",
    "            max_iterations=3\n",
    "        )\n",
    "\n",
    "        print(f\"--- Processing building: {BUILDING_NAME} for model: {MODEL_NAME} ---\")\n",
    "        \n",
    "        try:\n",
    "            for query_info in target_building_data.get('queries', []):\n",
    "                query_id = query_info.get('query_id')\n",
    "                ground_truth_sparql = query_info.get('sparql_query')\n",
    "\n",
    "                if not ground_truth_sparql:\n",
    "                    print(f\"‚ö†Ô∏è Warning: Skipping Query Group ID {query_id} (no ground truth SPARQL).\")\n",
    "                    continue\n",
    "                    \n",
    "                if \"prefix\" not in ground_truth_sparql.lower():\n",
    "                    ground_truth_sparql = BRICK_PREFIXES + ground_truth_sparql\n",
    "\n",
    "                print(f\"\\n--- Processing Query Group ID: {query_id} ---\")\n",
    "                \n",
    "                for question_obj in query_info.get('questions', []):\n",
    "                    question_text = question_obj.get('text')\n",
    "                    if not question_text:\n",
    "                        continue\n",
    "\n",
    "                    if check_if_question_exists(question_text, LOG_FILE, MODEL_NAME):\n",
    "                        continue\n",
    "\n",
    "                    eval_data = {\n",
    "                        'query_id': query_id,\n",
    "                        'question_number': question_obj.get('question_number', 'N/A'),\n",
    "                        'source': question_obj.get('source', 'N/A'),\n",
    "                        'question': question_text,\n",
    "                        'ground_truth_sparql': ground_truth_sparql\n",
    "                    }\n",
    "                    \n",
    "                    agent.refine_and_evaluate_query(\n",
    "                        eval_data=eval_data, \n",
    "                        logger=logger, \n",
    "                        prefixes=BRICK_PREFIXES,\n",
    "                        knowledge_graph_content=KNOWLEDGE_GRAPH_CONTENT\n",
    "                    )\n",
    "        \n",
    "        finally:\n",
    "            logger.close()\n",
    "\n",
    "\n",
    "for num_triples in [100, 5000]:\n",
    "    run_all_buildings(model_name=\"openai/o3-mini\", num_triples=num_triples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
